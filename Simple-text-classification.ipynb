{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Setfit Framework"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You must first open this notebook in google colab "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/aqsone/KULLA-setfit/blob/main/Simple-text-classification.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses, models, datasets, evaluation\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import torch\n",
    "\n",
    "def set_seed(seed):\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_pairs_generation(sentences, labels, pairs):\n",
    "\t# initialize two empty lists to hold the (sentence, sentence) pairs and\n",
    "\t# labels to indicate if a pair is positive or negative\n",
    "\n",
    "  numClassesList = np.unique(labels)\n",
    "  idx = [np.where(labels == i)[0] for i in numClassesList]\n",
    "\n",
    "  for idxA in range(len(sentences)):      \n",
    "    currentSentence = sentences[idxA]\n",
    "    label = labels[idxA]\n",
    "    idxB = np.random.choice(idx[np.where(numClassesList==label)[0][0]])\n",
    "    posSentence = sentences[idxB]\n",
    "\t\t  # prepare a positive pair and update the sentences and labels\n",
    "\t\t  # lists, respectively\n",
    "    pairs.append(InputExample(texts=[currentSentence, posSentence], label=1.0))\n",
    "\n",
    "    negIdx = np.where(labels != label)[0]\n",
    "    negSentence = sentences[np.random.choice(negIdx)]\n",
    "\t\t  # prepare a negative pair of images and update our lists\n",
    "    pairs.append(InputExample(texts=[currentSentence, negSentence], label=0.0))\n",
    "  \n",
    "\t# return a 2-tuple of our image pairs and labels\n",
    "  return (pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SST-2\n",
    "# Load SST-2 dataset into a pandas dataframe.\n",
    "\n",
    "train_df = pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv', delimiter='\\t', header=None)\n",
    "\n",
    "# Load the test dataset into a pandas dataframe.\n",
    "eval_df = pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/test.tsv', delimiter='\\t', header=None)\n",
    "\n",
    "text_col=train_df.columns.values[0] \n",
    "category_col=train_df.columns.values[1]\n",
    "\n",
    "x_eval = eval_df[text_col].values.tolist()\n",
    "y_eval = eval_df[category_col].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title SetFit\n",
    "st_model = 'paraphrase-mpnet-base-v2' #@param ['paraphrase-mpnet-base-v2', 'all-mpnet-base-v1', 'all-mpnet-base-v2', 'stsb-mpnet-base-v2', 'all-MiniLM-L12-v2', 'paraphrase-albert-small-v2', 'all-roberta-large-v1']\n",
    "num_training = 32 #@param [\"8\", \"16\", \"32\", \"54\", \"128\", \"256\", \"512\"] {type:\"raw\"}\n",
    "num_itr = 5 #@param [\"1\", \"2\", \"3\", \"4\", \"5\", \"10\"] {type:\"raw\"}\n",
    "plot2d_checkbox = False #@param {type: 'boolean'}\n",
    "\n",
    "set_seed(0)\n",
    "# Equal samples per class training\n",
    "train_df_sample = pd.concat([train_df[train_df[1]==0].sample(num_training), train_df[train_df[1]==1].sample(num_training)])\n",
    "x_train = train_df_sample[text_col].values.tolist()\n",
    "y_train = train_df_sample[category_col].values.tolist()\n",
    "\n",
    "train_examples = [] \n",
    "for x in range(num_itr):\n",
    "  train_examples = sentence_pairs_generation(np.array(x_train), np.array(y_train), train_examples)\n",
    "\n",
    "orig_model = SentenceTransformer(st_model)\n",
    "model = SentenceTransformer(st_model)\n",
    "\n",
    "# S-BERT adaptation \n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n",
    "train_loss = losses.CosineSimilarityLoss(model)\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=1, warmup_steps=10, show_progress_bar=True)\n",
    "\n",
    "# No Fit\n",
    "X_train_noFT = orig_model.encode(x_train)\n",
    "X_eval_noFT = orig_model.encode(x_eval)\n",
    "\n",
    "sgd =  LogisticRegression()\n",
    "sgd.fit(X_train_noFT, y_train)\n",
    "y_pred_eval_sgd = sgd.predict(X_eval_noFT)\n",
    "\n",
    "print('Acc. No Fit', accuracy_score(y_eval, y_pred_eval_sgd))\n",
    "\n",
    "# With Fit (SetFit)\n",
    "X_train = model.encode(x_train)\n",
    "X_eval = model.encode(x_eval)\n",
    "\n",
    "sgd =  LogisticRegression()\n",
    "sgd.fit(X_train, y_train)\n",
    "y_pred_eval_sgd = sgd.predict(X_eval)\n",
    "\n",
    "print('Acc. SetFit', accuracy_score(y_eval, y_pred_eval_sgd))\n",
    "\n",
    "#Plot 2-D 2x2 figures\n",
    "if plot2d_checkbox:   \n",
    "\n",
    "  plt.figure(figsize=(20,10))\n",
    "\n",
    "#Plot X_train_noFit\n",
    "  X_embedded = TSNE(n_components=2).fit_transform(np.array(X_train_noFT))\n",
    "  plt.subplot(221)\n",
    "  plt.title('X_train No Fit')\n",
    "\n",
    "  for i, t in enumerate(set(np.array(y_train))):\n",
    "      idx = np.array(y_train) == t\n",
    "      plt.scatter(X_embedded[idx, 0], X_embedded[idx, 1], label=t)   \n",
    "\n",
    "  plt.legend(bbox_to_anchor=(1, 1));\n",
    "\n",
    "#Plot X_eval noFit\n",
    "  X_embedded = TSNE(n_components=2).fit_transform(np.array(X_eval_noFT))\n",
    "  plt.subplot(223)\n",
    "  plt.title('X_eval No Fit')\n",
    "\n",
    "  for i, t in enumerate(set(np.array(y_eval))):\n",
    "      idx = np.array(y_eval) == t\n",
    "      plt.scatter(X_embedded[idx, 0], X_embedded[idx, 1], label=t)   \n",
    "\n",
    "  plt.legend(bbox_to_anchor=(1, 1));\n",
    "\n",
    "\n",
    "#Plot X_train SetFit\n",
    "  X_embedded = TSNE(n_components=2).fit_transform(np.array(X_train))\n",
    "\n",
    "  plt.subplot(222)\n",
    "  plt.title('X_train SetFit')\n",
    "\n",
    "  for i, t in enumerate(set(np.array(y_train))):\n",
    "      idx = np.array(y_train) == t\n",
    "      plt.scatter(X_embedded[idx, 0], X_embedded[idx, 1], label=t)   \n",
    "\n",
    "  plt.legend(bbox_to_anchor=(1, 1));\n",
    "\n",
    "#Plot X_eval SetFit\n",
    "  X_embedded = TSNE(n_components=2).fit_transform(np.array(X_eval))\n",
    "  plt.subplot(224)\n",
    "  plt.title('X_eval SetFit')\n",
    "\n",
    "  for i, t in enumerate(set(np.array(y_eval))):\n",
    "      idx = np.array(y_eval) == t\n",
    "      plt.scatter(X_embedded[idx, 0], X_embedded[idx, 1], label=t)   \n",
    "\n",
    "  plt.legend(bbox_to_anchor=(1, 1));\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
